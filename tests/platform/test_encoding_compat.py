"""ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ãƒ»æ–‡å­—åˆ—å‡¦ç†ã®ã‚¯ãƒ­ã‚¹ãƒ—ãƒ©ãƒƒãƒˆãƒ•ã‚©ãƒ¼ãƒ ãƒ†ã‚¹ãƒˆ

UTF-8ã€SJISã€ãƒ­ã‚±ãƒ¼ãƒ«å›ºæœ‰ã®æ–‡å­—åˆ—å‡¦ç†ãŒãƒ—ãƒ©ãƒƒãƒˆãƒ•ã‚©ãƒ¼ãƒ é–“ã§ä¸€è²«ã™ã‚‹ã“ã¨ã‚’ç¢ºèªã€‚
"""

import locale
import sys
from pathlib import Path

import pytest


class TestUTF8Consistency:
    """UTF-8 ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ã®ã‚¯ãƒ­ã‚¹ãƒ—ãƒ©ãƒƒãƒˆãƒ•ã‚©ãƒ¼ãƒ ä¸€è²«æ€§"""

    def test_utf8_encode_decode_consistency(self):
        """UTF-8 ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰ãƒ»ãƒ‡ã‚³ãƒ¼ãƒ‰ãŒå¯é€†çš„"""
        original_text = "æ—¥æœ¬èªãƒ†ã‚­ã‚¹ãƒˆ ğŸ‰ English"

        # ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰ â†’ ãƒ‡ã‚³ãƒ¼ãƒ‰
        encoded = original_text.encode("utf-8")
        decoded = encoded.decode("utf-8")

        assert decoded == original_text

    def test_utf8_file_io(self, tmp_path):
        """UTF-8 ãƒ•ã‚¡ã‚¤ãƒ« I/O ãŒãƒ—ãƒ©ãƒƒãƒˆãƒ•ã‚©ãƒ¼ãƒ å¯¾å¿œ"""
        test_file = tmp_path / "utf8_test.txt"
        test_text = "æ—¥æœ¬èª ğŸ‰ í•œê¸€ Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©"

        # æ›¸ãè¾¼ã¿
        test_file.write_text(test_text, encoding="utf-8")

        # èª­ã¿è¾¼ã¿
        read_text = test_file.read_text(encoding="utf-8")

        assert read_text == test_text

    def test_utf8_bytes_preservation(self):
        """UTF-8 ãƒã‚¤ãƒˆåˆ—ãŒå¤šãƒ—ãƒ©ãƒƒãƒˆãƒ•ã‚©ãƒ¼ãƒ é–“ã§åŒä¸€"""
        text = "ãƒ†ã‚¹ãƒˆ"

        # Windows ã§ã‚‚ Unix ã§ã‚‚åŒã˜ UTF-8 ãƒã‚¤ãƒˆåˆ—
        utf8_bytes = text.encode("utf-8")
        assert utf8_bytes == b'\xe3\x83\x86\xe3\x82\xb9\xe3\x83\x88'

        # ãƒ‡ã‚³ãƒ¼ãƒ‰å¯èƒ½
        decoded = utf8_bytes.decode("utf-8")
        assert decoded == text

    def test_utf8_bom_handling(self):
        """UTF-8 BOMï¼ˆByte Order Markï¼‰å‡¦ç†"""
        text = "ãƒ†ã‚¹ãƒˆ"

        # UTF-8 with BOM ã§ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰
        utf8_bom = text.encode("utf-8-sig")

        # BOM ã¯å…ˆé ­ 3 ãƒã‚¤ãƒˆ
        assert utf8_bom.startswith(b'\xef\xbb\xbf')

        # utf-8-sig ã§ãƒ‡ã‚³ãƒ¼ãƒ‰æ™‚ BOM ã¯å‰Šé™¤ã•ã‚Œã‚‹
        decoded = utf8_bom.decode("utf-8-sig")
        assert decoded == text  # BOM ãªã—

        # é€šå¸¸ã® utf-8 ã§ãƒ‡ã‚³ãƒ¼ãƒ‰ã™ã‚‹ã¨ BOM æ–‡å­—ãŒæ®‹ã‚‹
        decoded_with_bom = utf8_bom.decode("utf-8")
        assert decoded_with_bom.startswith("\ufeff")


class TestUnicodeNormalization:
    """Unicode æ­£è¦åŒ–ã®ã‚¯ãƒ­ã‚¹ãƒ—ãƒ©ãƒƒãƒˆãƒ•ã‚©ãƒ¼ãƒ å‡¦ç†"""

    def test_nfc_normalization(self):
        """NFCï¼ˆNormalization Form Cï¼‰æ­£è¦åŒ–"""
        import unicodedata

        # åˆæˆå¯èƒ½ãªæ–‡å­—
        decomposed = "Ã©"  # e + combining acute accent
        composed = "Ã©"    # single precomposed character

        # NFC æ­£è¦åŒ–ã§çµ±ä¸€
        nfc_decomposed = unicodedata.normalize("NFC", decomposed)
        nfc_composed = unicodedata.normalize("NFC", composed)

        # æ­£è¦åŒ–å¾Œã¯åŒä¸€
        assert nfc_decomposed == nfc_composed

    def test_nfd_normalization(self):
        """NFDï¼ˆNormalization Form Dï¼‰æ­£è¦åŒ–"""
        import unicodedata

        # åˆæˆæ–‡å­—
        text = "cafÃ©"

        # NFD ã§åˆ†è§£
        nfd = unicodedata.normalize("NFD", text)
        # NFC ã§å†åˆæˆ
        nfc = unicodedata.normalize("NFC", nfd)

        # NFC ã§æ­£è¦åŒ–å¾Œã¯åŒä¸€
        assert nfc == text

    def test_combining_characters(self):
        """çµåˆæ–‡å­—ã®å‡¦ç†"""
        import unicodedata

        # åŸºæœ¬æ–‡å­— + çµåˆè¨˜å·
        base = "a"
        combining_acute = "\u0301"  # combining acute accent
        combined = base + combining_acute

        # çµåˆæ–‡å­—ã¯è¤‡æ•°ãƒã‚¤ãƒˆ
        assert len(combined) == 2
        assert len(combined.encode("utf-8")) > 1


class TestLocaleSpecificString:
    """ãƒ­ã‚±ãƒ¼ãƒ«å›ºæœ‰ã®æ–‡å­—åˆ—å‡¦ç†"""

    def test_default_encoding_awareness(self):
        """ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ãŒãƒ—ãƒ©ãƒƒãƒˆãƒ•ã‚©ãƒ¼ãƒ ãƒ»ãƒ­ã‚±ãƒ¼ãƒ«ä¾å­˜"""
        default_encoding = locale.getpreferredencoding(False)

        # ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°åãŒæœ‰åŠ¹
        assert default_encoding is not None
        assert len(default_encoding) > 0

        # ãƒ†ã‚­ã‚¹ãƒˆã‚’ã“ã®ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ã§ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰å¯èƒ½ï¼ˆæ—¥æœ¬èªASCIIäº’æ›ãƒ†ã‚­ã‚¹ãƒˆï¼‰
        test_text = "hello"
        try:
            encoded = test_text.encode(default_encoding)
            assert encoded is not None
        except (LookupError, UnicodeEncodeError):
            # ãƒ­ã‚±ãƒ¼ãƒ«è¨€èªã«å¯¾å¿œã—ã¦ã„ãªã„å¯èƒ½æ€§
            pass

    def test_filesystem_default_encoding(self):
        """ãƒ•ã‚¡ã‚¤ãƒ«ã‚·ã‚¹ãƒ†ãƒ ã®ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°"""
        import sys

        # sys.getfilesystemencoding() ãŒãƒ—ãƒ©ãƒƒãƒˆãƒ•ã‚©ãƒ¼ãƒ å›ºæœ‰
        fs_encoding = sys.getfilesystemencoding()

        if sys.platform == "win32":
            # Windows ã§ã¯ utf-8 ã¾ãŸã¯ mbcs (ANSI)
            assert fs_encoding.lower() in ["utf-8", "mbcs", "cp932"]
        else:
            # Unix/Linux ã§ã¯ utf-8
            assert fs_encoding.lower() in ["utf-8", "utf8"]

    def test_stdin_stdout_encoding(self):
        """æ¨™æº–å…¥å‡ºåŠ›ã®ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°"""
        import sys

        # stdin/stdout ã®ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°
        stdin_encoding = sys.stdin.encoding
        stdout_encoding = sys.stdout.encoding

        # ä¸¡æ–¹ãŒã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°åã‚’æŒã¤
        assert stdin_encoding is not None or stdout_encoding is not None


class TestStringComparison:
    """ã‚¯ãƒ­ã‚¹ãƒ—ãƒ©ãƒƒãƒˆãƒ•ã‚©ãƒ¼ãƒ æ–‡å­—åˆ—æ¯”è¼ƒ"""

    def test_case_sensitive_comparison(self):
        """å¤§æ–‡å­—å°æ–‡å­—åŒºåˆ¥"""
        text1 = "Test"
        text2 = "test"

        # Python ã®æ–‡å­—åˆ—æ¯”è¼ƒã¯å¸¸ã«å¤§æ–‡å­—å°æ–‡å­—ã‚’åŒºåˆ¥
        assert text1 != text2

    def test_whitespace_handling(self):
        """ç©ºç™½æ–‡å­—ã®å‡¦ç†"""
        # ç•°ãªã‚‹ç©ºç™½æ–‡å­—
        space = " "          # U+0020 SPACE
        nbsp = "\u00A0"      # U+00A0 NO-BREAK SPACE
        em_space = "\u2003"  # U+2003 EM SPACE

        # ç•°ãªã‚‹æ–‡å­—ã¨ã—ã¦èªè­˜
        assert space != nbsp
        assert nbsp != em_space

    def test_line_ending_handling(self):
        """æ”¹è¡Œæ–‡å­—ã®å‡¦ç†"""
        # ç•°ãªã‚‹æ”¹è¡Œ
        lf = "line1\nline2"      # Unix: LF
        crlf = "line1\r\nline2"  # Windows: CRLF
        cr = "line1\rline2"      # Old Mac: CR

        # ç•°ãªã‚‹æ–‡å­—åˆ—ã¨ã—ã¦ä¿æŒ
        assert lf != crlf
        assert crlf != cr

    def test_unicode_escape_sequences(self):
        """Unicode ã‚¨ã‚¹ã‚±ãƒ¼ãƒ—ã‚·ãƒ¼ã‚±ãƒ³ã‚¹"""
        # ç•°ãªã‚‹è¡¨è¨˜æ–¹æ³•
        literal = "æ—¥æœ¬èª"
        escaped = "\u65e5\u672c\u8a9e"

        # åŒä¸€æ–‡å­—ã¨ã—ã¦èªè­˜
        assert literal == escaped


class TestStringFormatting:
    """ãƒ—ãƒ©ãƒƒãƒˆãƒ•ã‚©ãƒ¼ãƒ åˆ¥æ–‡å­—åˆ—ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆ"""

    def test_format_with_unicode(self):
        """Unicode ã‚’å«ã‚€ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆ"""
        template = "Hello {name} ğŸ‰"
        result = template.format(name="ä¸–ç•Œ")

        assert "ä¸–ç•Œ" in result
        assert "ğŸ‰" in result

    def test_f_string_with_unicode(self):
        """f-string ã§ã® Unicode å‡¦ç†"""
        name = "ãƒ†ã‚¹ãƒˆ"
        result = f"çµæœ: {name}"

        assert "ãƒ†ã‚¹ãƒˆ" in result
        assert "çµæœ" in result

    def test_string_multiplication_with_unicode(self):
        """Unicode æ–‡å­—ã®ç¹°ã‚Šè¿”ã—"""
        emoji = "ğŸ¯"
        repeated = emoji * 5

        assert len(repeated) == 5
        assert "ğŸ¯" in repeated


class TestErrorHandling:
    """ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°é–¢é€£ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°"""

    def test_encode_error_handling(self):
        """ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰ã‚¨ãƒ©ãƒ¼å‡¦ç†"""
        text = "Hello ä¸–ç•Œ ğŸ‰"

        # UTF-8 ã¯ã™ã¹ã¦ã®æ–‡å­—ã‚’ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰å¯èƒ½
        utf8_result = text.encode("utf-8")
        assert utf8_result is not None

        # ASCII ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰ã¯ã‚¨ãƒ©ãƒ¼
        with pytest.raises(UnicodeEncodeError):
            text.encode("ascii")

    def test_encode_error_strategy(self):
        """ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰ã‚¨ãƒ©ãƒ¼ã®æˆ¦ç•¥åˆ¥å‡¦ç†"""
        text = "Hello ä¸–ç•Œ"

        # 'replace' strategy: ç½®æ›
        result_replace = text.encode("ascii", errors="replace")
        assert b"Hello" in result_replace

        # 'ignore' strategy: ã‚¹ã‚­ãƒƒãƒ—
        result_ignore = text.encode("ascii", errors="ignore")
        assert b"Hello" in result_ignore

        # 'backslashreplace' strategy: ãƒãƒƒã‚¯ã‚¹ãƒ©ãƒƒã‚·ãƒ¥ã§è¡¨ç¾
        result_backslash = text.encode("ascii", errors="backslashreplace")
        assert b"\\u" in result_backslash or b"Hello" in result_backslash

    def test_decode_error_handling(self):
        """ãƒ‡ã‚³ãƒ¼ãƒ‰ã‚¨ãƒ©ãƒ¼å‡¦ç†"""
        # ç„¡åŠ¹ãª UTF-8 ãƒã‚¤ãƒˆåˆ—
        invalid_utf8 = b'\xff\xfe'

        # ãƒ‡ã‚³ãƒ¼ãƒ‰ã‚¨ãƒ©ãƒ¼
        with pytest.raises(UnicodeDecodeError):
            invalid_utf8.decode("utf-8")

        # 'replace' strategy ã§ç½®æ›æ–‡å­—ã‚’ä½¿ç”¨
        result = invalid_utf8.decode("utf-8", errors="replace")
        assert result is not None


class TestFileEncodingMigration:
    """ãƒ•ã‚¡ã‚¤ãƒ«ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ç§»è¡Œãƒ»å¤‰æ›ãƒ†ã‚¹ãƒˆ"""

    def test_utf8_to_utf16_conversion(self, tmp_path):
        """UTF-8 â†’ UTF-16 å¤‰æ›"""
        test_file_utf8 = tmp_path / "test_utf8.txt"
        test_file_utf16 = tmp_path / "test_utf16.txt"

        text = "ãƒ†ã‚¹ãƒˆãƒ†ã‚­ã‚¹ãƒˆ"

        # UTF-8 ã«æ›¸ãè¾¼ã¿
        test_file_utf8.write_text(text, encoding="utf-8")

        # èª­ã¿è¾¼ã¿
        read_text = test_file_utf8.read_text(encoding="utf-8")

        # UTF-16 ã«æ›¸ãè¾¼ã¿
        test_file_utf16.write_text(read_text, encoding="utf-16")

        # UTF-16 ã‹ã‚‰èª­ã¿è¾¼ã¿
        text_from_utf16 = test_file_utf16.read_text(encoding="utf-16")

        assert text == text_from_utf16

    def test_encoding_detection(self):
        """ãƒ†ã‚­ã‚¹ãƒˆã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ã®æ¤œå‡ºï¼ˆæ¨å®šï¼‰"""
        # è¤‡æ•°ã®ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°
        text = "Hello World"

        utf8_bytes = text.encode("utf-8")
        utf16_bytes = text.encode("utf-16")
        sjis_bytes = text.encode("shift_jis")

        # ASCII äº’æ›ãƒ†ã‚­ã‚¹ãƒˆã¯ã™ã¹ã¦ã®ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ã§åŒä¸€
        assert utf8_bytes == b'Hello World'
        assert sjis_bytes == b'Hello World'

        # UTF-16 ã¯ BOM ã‚’å«ã‚€å¯èƒ½æ€§ã‚ã‚Š
        assert b'H' in utf16_bytes


class TestJapaneseCharacterHandling:
    """æ—¥æœ¬èªæ–‡å­—å‡¦ç†ï¼ˆãƒ†ã‚¹ãƒˆå¯¾è±¡ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆè¨€èªï¼‰"""

    def test_hiragana_katakana_distinction(self):
        """ã²ã‚‰ãŒãªãƒ»ã‚«ã‚¿ã‚«ãƒŠåŒºåˆ¥"""
        hiragana = "ã‚ã„ã†ãˆãŠ"
        katakana = "ã‚¢ã‚¤ã‚¦ã‚¨ã‚ª"

        # ç•°ãªã‚‹æ–‡å­—ã¨ã—ã¦èªè­˜
        assert hiragana != katakana

    def test_kanji_handling(self):
        """æ¼¢å­—å‡¦ç†"""
        kanji = "æ—¥æœ¬èª"

        # UTF-8 ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰
        utf8_bytes = kanji.encode("utf-8")
        assert len(utf8_bytes) == 9  # 3 æ–‡å­— Ã— 3 ãƒã‚¤ãƒˆ

        # ãƒ‡ã‚³ãƒ¼ãƒ‰å¯èƒ½
        decoded = utf8_bytes.decode("utf-8")
        assert decoded == kanji

    def test_mixed_japanese_english(self):
        """æ—¥æœ¬èªãƒ»è‹±èªæ··åœ¨ãƒ†ã‚­ã‚¹ãƒˆ"""
        mixed = "yadon-agents ãƒ¤ãƒ‰ãƒ³ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ ğŸ¯"

        # é•·ã•ã¯æ–‡å­—æ•°ï¼ˆãƒã‚¤ãƒˆæ•°ã§ã¯ãªã„ï¼‰
        assert len(mixed) > 0

        # å„éƒ¨åˆ†ã‚’æŠ½å‡ºå¯èƒ½
        parts = mixed.split()
        assert len(parts) >= 1

    def test_japanese_punctuation(self):
        """æ—¥æœ¬èªå¥èª­ç‚¹"""
        text = "ã“ã‚Œã¯ãƒ†ã‚¹ãƒˆã§ã™ã€‚ã€Œã¯ã„ã€ã¨è¨€ã„ã¾ã—ãŸã€‚"

        # å¥ç‚¹ U+3002ã€èª­ç‚¹ U+3001ã€æ‹¬å¼§ã‚‚å«ã‚€
        assert "ã€‚" in text
        assert "ã€Œ" in text
        assert "ã€" in text

    def test_vertical_text_characters(self):
        """ç¸¦æ›¸ãç”¨æ–‡å­—å‡¦ç†"""
        # ä»®åã®ç¸¦æ›¸ãç”¨æ–‡å­—ã‚‚å‡¦ç†å¯èƒ½
        text = "ã“ã‚Œã¯æ—¥æœ¬èªã®ãƒ†ã‚¹ãƒˆ"

        # UTF-8 ã§å‡¦ç†å¯èƒ½
        encoded = text.encode("utf-8")
        decoded = encoded.decode("utf-8")

        assert decoded == text
